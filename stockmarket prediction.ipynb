{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1573727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47b75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500=yf.Ticker(\"^GSPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23da3917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Open       High        Low      Close  Volume  \\\n",
      "Date                                                                            \n",
      "1927-12-30 00:00:00-05:00  17.660000  17.660000  17.660000  17.660000       0   \n",
      "1928-01-03 00:00:00-05:00  17.760000  17.760000  17.760000  17.760000       0   \n",
      "1928-01-04 00:00:00-05:00  17.719999  17.719999  17.719999  17.719999       0   \n",
      "1928-01-05 00:00:00-05:00  17.549999  17.549999  17.549999  17.549999       0   \n",
      "1928-01-06 00:00:00-05:00  17.660000  17.660000  17.660000  17.660000       0   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "1927-12-30 00:00:00-05:00        0.0           0.0  \n",
      "1928-01-03 00:00:00-05:00        0.0           0.0  \n",
      "1928-01-04 00:00:00-05:00        0.0           0.0  \n",
      "1928-01-05 00:00:00-05:00        0.0           0.0  \n",
      "1928-01-06 00:00:00-05:00        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "SP500 = yf.Ticker(\"^GSPC\") \n",
    "\n",
    "\n",
    "SP500_data = SP500.history(period=\"max\")\n",
    "\n",
    "print(SP500_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f687eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows and columns: (24505, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows and columns:\", SP500_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8b3e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24505, 7)\n"
     ]
    }
   ],
   "source": [
    "print(yf.Ticker(\"^GSPC\").history(period=\"max\").shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6cf193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['1927-12-30 00:00:00-05:00', '1928-01-03 00:00:00-05:00',\n",
      "               '1928-01-04 00:00:00-05:00', '1928-01-05 00:00:00-05:00',\n",
      "               '1928-01-06 00:00:00-05:00', '1928-01-09 00:00:00-05:00',\n",
      "               '1928-01-10 00:00:00-05:00', '1928-01-11 00:00:00-05:00',\n",
      "               '1928-01-12 00:00:00-05:00', '1928-01-13 00:00:00-05:00',\n",
      "               ...\n",
      "               '2025-07-10 00:00:00-04:00', '2025-07-11 00:00:00-04:00',\n",
      "               '2025-07-14 00:00:00-04:00', '2025-07-15 00:00:00-04:00',\n",
      "               '2025-07-16 00:00:00-04:00', '2025-07-17 00:00:00-04:00',\n",
      "               '2025-07-18 00:00:00-04:00', '2025-07-21 00:00:00-04:00',\n",
      "               '2025-07-22 00:00:00-04:00', '2025-07-23 00:00:00-04:00'],\n",
      "              dtype='datetime64[ns, America/New_York]', name='Date', length=24505, freq=None)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf; print(yf.Ticker(\"^GSPC\").history(period=\"max\").index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cdbc7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf; yf.Ticker(\"^GSPC\").history(period=\"max\").plot.line(y=\"Close\", use_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435095e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data = yf.Ticker(\"^GSPC\").history(period=\"max\").drop(columns=[\"Dividends\", \"Stock Splits\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2656b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data = yf.Ticker(\"^GSPC\").history(period=\"max\"); sp500_data[\"Tomorrow\"] = sp500_data[\"Close\"].shift(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ce9def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927-12-30 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-03 00:00:00-05:00</th>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-04 00:00:00-05:00</th>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-05 00:00:00-05:00</th>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-06 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17 00:00:00-04:00</th>\n",
       "      <td>6263.399902</td>\n",
       "      <td>6304.689941</td>\n",
       "      <td>6262.270020</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>5512290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6296.790039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18 00:00:00-04:00</th>\n",
       "      <td>6312.950195</td>\n",
       "      <td>6315.609863</td>\n",
       "      <td>6285.270020</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>5184700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6305.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21 00:00:00-04:00</th>\n",
       "      <td>6304.740234</td>\n",
       "      <td>6336.080078</td>\n",
       "      <td>6303.790039</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>5010840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6309.620117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 00:00:00-04:00</th>\n",
       "      <td>6306.600098</td>\n",
       "      <td>6316.120117</td>\n",
       "      <td>6281.709961</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>5662040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6335.709961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23 00:00:00-04:00</th>\n",
       "      <td>6326.899902</td>\n",
       "      <td>6347.089844</td>\n",
       "      <td>6317.490234</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1416650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24505 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1927-12-30 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "1928-01-03 00:00:00-05:00    17.760000    17.760000    17.760000    17.760000   \n",
       "1928-01-04 00:00:00-05:00    17.719999    17.719999    17.719999    17.719999   \n",
       "1928-01-05 00:00:00-05:00    17.549999    17.549999    17.549999    17.549999   \n",
       "1928-01-06 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-07-17 00:00:00-04:00  6263.399902  6304.689941  6262.270020  6297.359863   \n",
       "2025-07-18 00:00:00-04:00  6312.950195  6315.609863  6285.270020  6296.790039   \n",
       "2025-07-21 00:00:00-04:00  6304.740234  6336.080078  6303.790039  6305.600098   \n",
       "2025-07-22 00:00:00-04:00  6306.600098  6316.120117  6281.709961  6309.620117   \n",
       "2025-07-23 00:00:00-04:00  6326.899902  6347.089844  6317.490234  6335.709961   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits     Tomorrow  \n",
       "Date                                                                         \n",
       "1927-12-30 00:00:00-05:00           0        0.0           0.0    17.760000  \n",
       "1928-01-03 00:00:00-05:00           0        0.0           0.0    17.719999  \n",
       "1928-01-04 00:00:00-05:00           0        0.0           0.0    17.549999  \n",
       "1928-01-05 00:00:00-05:00           0        0.0           0.0    17.660000  \n",
       "1928-01-06 00:00:00-05:00           0        0.0           0.0    17.500000  \n",
       "...                               ...        ...           ...          ...  \n",
       "2025-07-17 00:00:00-04:00  5512290000        0.0           0.0  6296.790039  \n",
       "2025-07-18 00:00:00-04:00  5184700000        0.0           0.0  6305.600098  \n",
       "2025-07-21 00:00:00-04:00  5010840000        0.0           0.0  6309.620117  \n",
       "2025-07-22 00:00:00-04:00  5662040000        0.0           0.0  6335.709961  \n",
       "2025-07-23 00:00:00-04:00  1416650000        0.0           0.0          NaN  \n",
       "\n",
       "[24505 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c3f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows and columns: (24505, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows and columns:\", SP500_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c32a65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data[\"Target\"]=(sp500_data[\"Tomorrow\"]>sp500_data[\"Close\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18b16821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927-12-30 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-03 00:00:00-05:00</th>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-04 00:00:00-05:00</th>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-05 00:00:00-05:00</th>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928-01-06 00:00:00-05:00</th>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17 00:00:00-04:00</th>\n",
       "      <td>6263.399902</td>\n",
       "      <td>6304.689941</td>\n",
       "      <td>6262.270020</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>5512290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18 00:00:00-04:00</th>\n",
       "      <td>6312.950195</td>\n",
       "      <td>6315.609863</td>\n",
       "      <td>6285.270020</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>5184700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21 00:00:00-04:00</th>\n",
       "      <td>6304.740234</td>\n",
       "      <td>6336.080078</td>\n",
       "      <td>6303.790039</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>5010840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 00:00:00-04:00</th>\n",
       "      <td>6306.600098</td>\n",
       "      <td>6316.120117</td>\n",
       "      <td>6281.709961</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>5662040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23 00:00:00-04:00</th>\n",
       "      <td>6326.899902</td>\n",
       "      <td>6347.089844</td>\n",
       "      <td>6317.490234</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1416650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24505 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1927-12-30 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "1928-01-03 00:00:00-05:00    17.760000    17.760000    17.760000    17.760000   \n",
       "1928-01-04 00:00:00-05:00    17.719999    17.719999    17.719999    17.719999   \n",
       "1928-01-05 00:00:00-05:00    17.549999    17.549999    17.549999    17.549999   \n",
       "1928-01-06 00:00:00-05:00    17.660000    17.660000    17.660000    17.660000   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-07-17 00:00:00-04:00  6263.399902  6304.689941  6262.270020  6297.359863   \n",
       "2025-07-18 00:00:00-04:00  6312.950195  6315.609863  6285.270020  6296.790039   \n",
       "2025-07-21 00:00:00-04:00  6304.740234  6336.080078  6303.790039  6305.600098   \n",
       "2025-07-22 00:00:00-04:00  6306.600098  6316.120117  6281.709961  6309.620117   \n",
       "2025-07-23 00:00:00-04:00  6326.899902  6347.089844  6317.490234  6335.709961   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits     Tomorrow  \\\n",
       "Date                                                                          \n",
       "1927-12-30 00:00:00-05:00           0        0.0           0.0    17.760000   \n",
       "1928-01-03 00:00:00-05:00           0        0.0           0.0    17.719999   \n",
       "1928-01-04 00:00:00-05:00           0        0.0           0.0    17.549999   \n",
       "1928-01-05 00:00:00-05:00           0        0.0           0.0    17.660000   \n",
       "1928-01-06 00:00:00-05:00           0        0.0           0.0    17.500000   \n",
       "...                               ...        ...           ...          ...   \n",
       "2025-07-17 00:00:00-04:00  5512290000        0.0           0.0  6296.790039   \n",
       "2025-07-18 00:00:00-04:00  5184700000        0.0           0.0  6305.600098   \n",
       "2025-07-21 00:00:00-04:00  5010840000        0.0           0.0  6309.620117   \n",
       "2025-07-22 00:00:00-04:00  5662040000        0.0           0.0  6335.709961   \n",
       "2025-07-23 00:00:00-04:00  1416650000        0.0           0.0          NaN   \n",
       "\n",
       "                           Target  \n",
       "Date                               \n",
       "1927-12-30 00:00:00-05:00       1  \n",
       "1928-01-03 00:00:00-05:00       0  \n",
       "1928-01-04 00:00:00-05:00       0  \n",
       "1928-01-05 00:00:00-05:00       1  \n",
       "1928-01-06 00:00:00-05:00       0  \n",
       "...                           ...  \n",
       "2025-07-17 00:00:00-04:00       0  \n",
       "2025-07-18 00:00:00-04:00       1  \n",
       "2025-07-21 00:00:00-04:00       1  \n",
       "2025-07-22 00:00:00-04:00       1  \n",
       "2025-07-23 00:00:00-04:00       0  \n",
       "\n",
       "[24505 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03878e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24505, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "711149fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data=sp500_data.loc[\"1990-01-01\":].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ac6b0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02 00:00:00-05:00</th>\n",
       "      <td>353.399994</td>\n",
       "      <td>359.690002</td>\n",
       "      <td>351.980011</td>\n",
       "      <td>359.690002</td>\n",
       "      <td>162070000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03 00:00:00-05:00</th>\n",
       "      <td>359.690002</td>\n",
       "      <td>360.589996</td>\n",
       "      <td>357.890015</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>192330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04 00:00:00-05:00</th>\n",
       "      <td>358.760010</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>352.890015</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>177000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.200012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05 00:00:00-05:00</th>\n",
       "      <td>355.670013</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>351.350006</td>\n",
       "      <td>352.200012</td>\n",
       "      <td>158530000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.790009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08 00:00:00-05:00</th>\n",
       "      <td>352.200012</td>\n",
       "      <td>354.239990</td>\n",
       "      <td>350.540009</td>\n",
       "      <td>353.790009</td>\n",
       "      <td>140110000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349.619995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17 00:00:00-04:00</th>\n",
       "      <td>6263.399902</td>\n",
       "      <td>6304.689941</td>\n",
       "      <td>6262.270020</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>5512290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18 00:00:00-04:00</th>\n",
       "      <td>6312.950195</td>\n",
       "      <td>6315.609863</td>\n",
       "      <td>6285.270020</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>5184700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21 00:00:00-04:00</th>\n",
       "      <td>6304.740234</td>\n",
       "      <td>6336.080078</td>\n",
       "      <td>6303.790039</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>5010840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 00:00:00-04:00</th>\n",
       "      <td>6306.600098</td>\n",
       "      <td>6316.120117</td>\n",
       "      <td>6281.709961</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>5662040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23 00:00:00-04:00</th>\n",
       "      <td>6326.899902</td>\n",
       "      <td>6347.089844</td>\n",
       "      <td>6317.490234</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1416650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1990-01-02 00:00:00-05:00   353.399994   359.690002   351.980011   359.690002   \n",
       "1990-01-03 00:00:00-05:00   359.690002   360.589996   357.890015   358.760010   \n",
       "1990-01-04 00:00:00-05:00   358.760010   358.760010   352.890015   355.670013   \n",
       "1990-01-05 00:00:00-05:00   355.670013   355.670013   351.350006   352.200012   \n",
       "1990-01-08 00:00:00-05:00   352.200012   354.239990   350.540009   353.790009   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-07-17 00:00:00-04:00  6263.399902  6304.689941  6262.270020  6297.359863   \n",
       "2025-07-18 00:00:00-04:00  6312.950195  6315.609863  6285.270020  6296.790039   \n",
       "2025-07-21 00:00:00-04:00  6304.740234  6336.080078  6303.790039  6305.600098   \n",
       "2025-07-22 00:00:00-04:00  6306.600098  6316.120117  6281.709961  6309.620117   \n",
       "2025-07-23 00:00:00-04:00  6326.899902  6347.089844  6317.490234  6335.709961   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits     Tomorrow  \\\n",
       "Date                                                                          \n",
       "1990-01-02 00:00:00-05:00   162070000        0.0           0.0   358.760010   \n",
       "1990-01-03 00:00:00-05:00   192330000        0.0           0.0   355.670013   \n",
       "1990-01-04 00:00:00-05:00   177000000        0.0           0.0   352.200012   \n",
       "1990-01-05 00:00:00-05:00   158530000        0.0           0.0   353.790009   \n",
       "1990-01-08 00:00:00-05:00   140110000        0.0           0.0   349.619995   \n",
       "...                               ...        ...           ...          ...   \n",
       "2025-07-17 00:00:00-04:00  5512290000        0.0           0.0  6296.790039   \n",
       "2025-07-18 00:00:00-04:00  5184700000        0.0           0.0  6305.600098   \n",
       "2025-07-21 00:00:00-04:00  5010840000        0.0           0.0  6309.620117   \n",
       "2025-07-22 00:00:00-04:00  5662040000        0.0           0.0  6335.709961   \n",
       "2025-07-23 00:00:00-04:00  1416650000        0.0           0.0          NaN   \n",
       "\n",
       "                           Target  \n",
       "Date                               \n",
       "1990-01-02 00:00:00-05:00       0  \n",
       "1990-01-03 00:00:00-05:00       0  \n",
       "1990-01-04 00:00:00-05:00       0  \n",
       "1990-01-05 00:00:00-05:00       1  \n",
       "1990-01-08 00:00:00-05:00       0  \n",
       "...                           ...  \n",
       "2025-07-17 00:00:00-04:00       0  \n",
       "2025-07-18 00:00:00-04:00       1  \n",
       "2025-07-21 00:00:00-04:00       1  \n",
       "2025-07-22 00:00:00-04:00       1  \n",
       "2025-07-23 00:00:00-04:00       0  \n",
       "\n",
       "[8955 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bd3e208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=100, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=100, random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=100,min_samples_split=100,random_state=1)\n",
    "train=sp500_data.iloc[:-100]\n",
    "test=sp500_data.iloc[-100:]\n",
    "predictors = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "model.fit(train[predictors],train[\"Target\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a22389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "preds=model.predict(test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4e16cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca02a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series([0] * len(test), index=test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12815523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(test[\"Target\"], preds, zero_division=0)\n",
    "print(\"Precision Score:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44d6765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([test[\"Target\"], preds], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "575921a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns = [\"Actual\", \"Predicted\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32b66911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test, predictors, model):\n",
    "    model.fit(train[predictors],train[\"Target\"])\n",
    "    preds=model.predict(test[predictors])\n",
    "    preds=pd.Series(preds,index=test.index,name=\" predications\")\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc8495bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import pandas as pd\n",
    "\n",
    "def backtest(data, model, predictors, start=2500, step=250):\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[:i].copy()\n",
    "        test = data.iloc[i:i+step].copy()\n",
    "        \n",
    "        model.fit(train[predictors], train[\"Target\"])\n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds, index=test.index)\n",
    "        \n",
    "        combined = pd.concat([test[\"Target\"], preds], axis=1)\n",
    "        combined.columns = [\"Actual\", \"Predicted\"]\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "\n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9db09cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(sp500_data,model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be1c0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns = [\"Actual\", \"Predicted\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10b8163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example model and predictors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "predictors = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "# Run backtest and store results\n",
    "results = backtest(sp500_data, model, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa8bb37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "1    5933\n",
      "0     522\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results.columns = [\"Actual\", \"Predictions\"]\n",
    "print(results[\"Predictions\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a0c5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns = [\"Actual\", \"Predicted\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ed8abc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5383448508343165"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(results[\"Actual\"], results[\"Predicted\"], zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4227441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6455"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b779c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Actual  Predicted\n",
      "Date                                        \n",
      "1999-11-22 00:00:00-05:00       0          0\n",
      "1999-11-23 00:00:00-05:00       1          0\n",
      "1999-11-24 00:00:00-05:00       0          0\n",
      "1999-11-26 00:00:00-05:00       0          0\n",
      "1999-11-29 00:00:00-05:00       0          0\n",
      "Index(['Actual', 'Predicted'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(predictions.head())\n",
    "print(predictions.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47d9ec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1999-11-22 00:00:00-05:00    0.000155\n",
       "1999-11-23 00:00:00-05:00    0.000155\n",
       "1999-11-24 00:00:00-05:00    0.000155\n",
       "1999-11-26 00:00:00-05:00    0.000155\n",
       "1999-11-29 00:00:00-05:00    0.000155\n",
       "                               ...   \n",
       "2025-07-17 00:00:00-04:00    0.000155\n",
       "2025-07-18 00:00:00-04:00    0.000155\n",
       "2025-07-21 00:00:00-04:00    0.000155\n",
       "2025-07-22 00:00:00-04:00    0.000155\n",
       "2025-07-23 00:00:00-04:00    0.000155\n",
       "Name: proportion, Length: 6455, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24f694bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n"
     ]
    }
   ],
   "source": [
    "print(predictions.index.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0a3fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fac16349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date  Actual  Predicted\n",
      "0 1999-11-22 00:00:00-05:00       0          0\n",
      "1 1999-11-23 00:00:00-05:00       1          0\n",
      "2 1999-11-24 00:00:00-05:00       0          0\n",
      "3 1999-11-26 00:00:00-05:00       0          0\n",
      "4 1999-11-29 00:00:00-05:00       0          0\n",
      "Index(['Date', 'Actual', 'Predicted'], dtype='object')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(predictions.head())\n",
    "print(predictions.columns)\n",
    "print(predictions.index.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19ecf311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000155\n",
       "1       0.000155\n",
       "2       0.000155\n",
       "3       0.000155\n",
       "4       0.000155\n",
       "          ...   \n",
       "6450    0.000155\n",
       "6451    0.000155\n",
       "6452    0.000155\n",
       "6453    0.000155\n",
       "6454    0.000155\n",
       "Name: proportion, Length: 6455, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.index.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e56602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "1    0.58\n",
      "0    0.42\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.concat([test[\"Target\"], preds], axis=1); predictions.columns = [\"Target\", \"Predictions\"]; print(predictions[\"Target\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d181b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "0    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(predictions[\"Predictions\"].value_counts(normalize=True).rename(\"proportion\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "695a5625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1    0.58\n",
       "0    0.42\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"Target\"].value_counts()/predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da6b013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [2, 5, 60, 250, 1000]\n",
    "new_predictors = []\n",
    "\n",
    "for horizon in horizons:\n",
    "    rolling_averages = sp500_data[\"Close\"].rolling(horizon).mean()\n",
    "    \n",
    "    ratio_column = f\"Close_Ratio_{horizon}\"\n",
    "    sp500_data[ratio_column] = sp500_data[\"Close\"] / rolling_averages\n",
    "    \n",
    "    trend_column = f\"Trend_{horizon}\"\n",
    "    sp500_data[trend_column] = sp500_data[\"Target\"].shift(1).rolling(horizon).sum()\n",
    "    \n",
    "    new_predictors += [ratio_column, trend_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9128adf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow</th>\n",
       "      <th>Target</th>\n",
       "      <th>Close_Ratio_2</th>\n",
       "      <th>Trend_2</th>\n",
       "      <th>Close_Ratio_5</th>\n",
       "      <th>Trend_5</th>\n",
       "      <th>Close_Ratio_60</th>\n",
       "      <th>Trend_60</th>\n",
       "      <th>Close_Ratio_250</th>\n",
       "      <th>Trend_250</th>\n",
       "      <th>Close_Ratio_1000</th>\n",
       "      <th>Trend_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02 00:00:00-05:00</th>\n",
       "      <td>353.399994</td>\n",
       "      <td>359.690002</td>\n",
       "      <td>351.980011</td>\n",
       "      <td>359.690002</td>\n",
       "      <td>162070000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03 00:00:00-05:00</th>\n",
       "      <td>359.690002</td>\n",
       "      <td>360.589996</td>\n",
       "      <td>357.890015</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>192330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04 00:00:00-05:00</th>\n",
       "      <td>358.760010</td>\n",
       "      <td>358.760010</td>\n",
       "      <td>352.890015</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>177000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.200012</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05 00:00:00-05:00</th>\n",
       "      <td>355.670013</td>\n",
       "      <td>355.670013</td>\n",
       "      <td>351.350006</td>\n",
       "      <td>352.200012</td>\n",
       "      <td>158530000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.790009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08 00:00:00-05:00</th>\n",
       "      <td>352.200012</td>\n",
       "      <td>354.239990</td>\n",
       "      <td>350.540009</td>\n",
       "      <td>353.790009</td>\n",
       "      <td>140110000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349.619995</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17 00:00:00-04:00</th>\n",
       "      <td>6263.399902</td>\n",
       "      <td>6304.689941</td>\n",
       "      <td>6262.270020</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>5512290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.004904</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.061360</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.085761</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.321859</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18 00:00:00-04:00</th>\n",
       "      <td>6312.950195</td>\n",
       "      <td>6315.609863</td>\n",
       "      <td>6285.270020</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>5184700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.058264</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.085099</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.321217</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21 00:00:00-04:00</th>\n",
       "      <td>6304.740234</td>\n",
       "      <td>6336.080078</td>\n",
       "      <td>6303.790039</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>5010840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003846</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.056992</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.086018</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.322543</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 00:00:00-04:00</th>\n",
       "      <td>6306.600098</td>\n",
       "      <td>6316.120117</td>\n",
       "      <td>6281.709961</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>5662040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.002384</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.055234</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.086153</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.322856</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-23 00:00:00-04:00</th>\n",
       "      <td>6326.899902</td>\n",
       "      <td>6347.089844</td>\n",
       "      <td>6317.490234</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1416650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002063</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.004231</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.057209</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.090059</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.327787</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8955 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1990-01-02 00:00:00-05:00   353.399994   359.690002   351.980011   359.690002   \n",
       "1990-01-03 00:00:00-05:00   359.690002   360.589996   357.890015   358.760010   \n",
       "1990-01-04 00:00:00-05:00   358.760010   358.760010   352.890015   355.670013   \n",
       "1990-01-05 00:00:00-05:00   355.670013   355.670013   351.350006   352.200012   \n",
       "1990-01-08 00:00:00-05:00   352.200012   354.239990   350.540009   353.790009   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-07-17 00:00:00-04:00  6263.399902  6304.689941  6262.270020  6297.359863   \n",
       "2025-07-18 00:00:00-04:00  6312.950195  6315.609863  6285.270020  6296.790039   \n",
       "2025-07-21 00:00:00-04:00  6304.740234  6336.080078  6303.790039  6305.600098   \n",
       "2025-07-22 00:00:00-04:00  6306.600098  6316.120117  6281.709961  6309.620117   \n",
       "2025-07-23 00:00:00-04:00  6326.899902  6347.089844  6317.490234  6335.709961   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits     Tomorrow  \\\n",
       "Date                                                                          \n",
       "1990-01-02 00:00:00-05:00   162070000        0.0           0.0   358.760010   \n",
       "1990-01-03 00:00:00-05:00   192330000        0.0           0.0   355.670013   \n",
       "1990-01-04 00:00:00-05:00   177000000        0.0           0.0   352.200012   \n",
       "1990-01-05 00:00:00-05:00   158530000        0.0           0.0   353.790009   \n",
       "1990-01-08 00:00:00-05:00   140110000        0.0           0.0   349.619995   \n",
       "...                               ...        ...           ...          ...   \n",
       "2025-07-17 00:00:00-04:00  5512290000        0.0           0.0  6296.790039   \n",
       "2025-07-18 00:00:00-04:00  5184700000        0.0           0.0  6305.600098   \n",
       "2025-07-21 00:00:00-04:00  5010840000        0.0           0.0  6309.620117   \n",
       "2025-07-22 00:00:00-04:00  5662040000        0.0           0.0  6335.709961   \n",
       "2025-07-23 00:00:00-04:00  1416650000        0.0           0.0          NaN   \n",
       "\n",
       "                           Target  Close_Ratio_2  Trend_2  Close_Ratio_5  \\\n",
       "Date                                                                       \n",
       "1990-01-02 00:00:00-05:00       0            NaN      NaN            NaN   \n",
       "1990-01-03 00:00:00-05:00       0       0.998706      NaN            NaN   \n",
       "1990-01-04 00:00:00-05:00       0       0.995675      0.0            NaN   \n",
       "1990-01-05 00:00:00-05:00       1       0.995098      0.0            NaN   \n",
       "1990-01-08 00:00:00-05:00       0       1.002252      1.0       0.993731   \n",
       "...                           ...            ...      ...            ...   \n",
       "2025-07-17 00:00:00-04:00       0       1.002680      2.0       1.004904   \n",
       "2025-07-18 00:00:00-04:00       1       0.999955      1.0       1.003627   \n",
       "2025-07-21 00:00:00-04:00       1       1.000699      1.0       1.003846   \n",
       "2025-07-22 00:00:00-04:00       1       1.000319      2.0       1.002384   \n",
       "2025-07-23 00:00:00-04:00       0       1.002063      2.0       1.004231   \n",
       "\n",
       "                           Trend_5  Close_Ratio_60  Trend_60  Close_Ratio_250  \\\n",
       "Date                                                                            \n",
       "1990-01-02 00:00:00-05:00      NaN             NaN       NaN              NaN   \n",
       "1990-01-03 00:00:00-05:00      NaN             NaN       NaN              NaN   \n",
       "1990-01-04 00:00:00-05:00      NaN             NaN       NaN              NaN   \n",
       "1990-01-05 00:00:00-05:00      NaN             NaN       NaN              NaN   \n",
       "1990-01-08 00:00:00-05:00      NaN             NaN       NaN              NaN   \n",
       "...                            ...             ...       ...              ...   \n",
       "2025-07-17 00:00:00-04:00      3.0        1.061360      39.0         1.085761   \n",
       "2025-07-18 00:00:00-04:00      3.0        1.058264      38.0         1.085099   \n",
       "2025-07-21 00:00:00-04:00      3.0        1.056992      38.0         1.086018   \n",
       "2025-07-22 00:00:00-04:00      4.0        1.055234      38.0         1.086153   \n",
       "2025-07-23 00:00:00-04:00      4.0        1.057209      38.0         1.090059   \n",
       "\n",
       "                           Trend_250  Close_Ratio_1000  Trend_1000  \n",
       "Date                                                                \n",
       "1990-01-02 00:00:00-05:00        NaN               NaN         NaN  \n",
       "1990-01-03 00:00:00-05:00        NaN               NaN         NaN  \n",
       "1990-01-04 00:00:00-05:00        NaN               NaN         NaN  \n",
       "1990-01-05 00:00:00-05:00        NaN               NaN         NaN  \n",
       "1990-01-08 00:00:00-05:00        NaN               NaN         NaN  \n",
       "...                              ...               ...         ...  \n",
       "2025-07-17 00:00:00-04:00      141.0          1.321859       530.0  \n",
       "2025-07-18 00:00:00-04:00      141.0          1.321217       529.0  \n",
       "2025-07-21 00:00:00-04:00      142.0          1.322543       529.0  \n",
       "2025-07-22 00:00:00-04:00      142.0          1.322856       530.0  \n",
       "2025-07-23 00:00:00-04:00      143.0          1.327787       531.0  \n",
       "\n",
       "[8955 rows x 19 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "622e0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data=sp500_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c1038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Tomorrow</th>\n",
       "      <th>Target</th>\n",
       "      <th>Close_Ratio_2</th>\n",
       "      <th>Trend_2</th>\n",
       "      <th>Close_Ratio_5</th>\n",
       "      <th>Trend_5</th>\n",
       "      <th>Close_Ratio_60</th>\n",
       "      <th>Trend_60</th>\n",
       "      <th>Close_Ratio_250</th>\n",
       "      <th>Trend_250</th>\n",
       "      <th>Close_Ratio_1000</th>\n",
       "      <th>Trend_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-12-14 00:00:00-05:00</th>\n",
       "      <td>465.730011</td>\n",
       "      <td>466.119995</td>\n",
       "      <td>462.459991</td>\n",
       "      <td>463.059998</td>\n",
       "      <td>275050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.839996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.028047</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.176082</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-12-15 00:00:00-05:00</th>\n",
       "      <td>463.059998</td>\n",
       "      <td>463.690002</td>\n",
       "      <td>461.839996</td>\n",
       "      <td>461.839996</td>\n",
       "      <td>331770000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463.339996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997329</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.025151</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.172676</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-12-16 00:00:00-05:00</th>\n",
       "      <td>461.859985</td>\n",
       "      <td>463.980011</td>\n",
       "      <td>461.859985</td>\n",
       "      <td>463.339996</td>\n",
       "      <td>284620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>466.380005</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000311</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.028274</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.176163</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-12-17 00:00:00-05:00</th>\n",
       "      <td>463.339996</td>\n",
       "      <td>466.380005</td>\n",
       "      <td>463.339996</td>\n",
       "      <td>466.380005</td>\n",
       "      <td>363750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.850006</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003270</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.004991</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.006561</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.034781</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.183537</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-12-20 00:00:00-05:00</th>\n",
       "      <td>466.380005</td>\n",
       "      <td>466.899994</td>\n",
       "      <td>465.529999</td>\n",
       "      <td>465.850006</td>\n",
       "      <td>255900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.299988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003784</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.005120</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.033359</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.181856</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-16 00:00:00-04:00</th>\n",
       "      <td>6254.500000</td>\n",
       "      <td>6268.120117</td>\n",
       "      <td>6201.589844</td>\n",
       "      <td>6263.700195</td>\n",
       "      <td>5177460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>1</td>\n",
       "      <td>1.001594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000073</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.059076</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.080486</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.315326</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-17 00:00:00-04:00</th>\n",
       "      <td>6263.399902</td>\n",
       "      <td>6304.689941</td>\n",
       "      <td>6262.270020</td>\n",
       "      <td>6297.359863</td>\n",
       "      <td>5512290000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.004904</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.061360</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.085761</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.321859</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-18 00:00:00-04:00</th>\n",
       "      <td>6312.950195</td>\n",
       "      <td>6315.609863</td>\n",
       "      <td>6285.270020</td>\n",
       "      <td>6296.790039</td>\n",
       "      <td>5184700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.058264</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.085099</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.321217</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-21 00:00:00-04:00</th>\n",
       "      <td>6304.740234</td>\n",
       "      <td>6336.080078</td>\n",
       "      <td>6303.790039</td>\n",
       "      <td>6305.600098</td>\n",
       "      <td>5010840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003846</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.056992</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.086018</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.322543</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-22 00:00:00-04:00</th>\n",
       "      <td>6306.600098</td>\n",
       "      <td>6316.120117</td>\n",
       "      <td>6281.709961</td>\n",
       "      <td>6309.620117</td>\n",
       "      <td>5662040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6335.709961</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.002384</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.055234</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.086153</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.322856</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7954 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "1993-12-14 00:00:00-05:00   465.730011   466.119995   462.459991   463.059998   \n",
       "1993-12-15 00:00:00-05:00   463.059998   463.690002   461.839996   461.839996   \n",
       "1993-12-16 00:00:00-05:00   461.859985   463.980011   461.859985   463.339996   \n",
       "1993-12-17 00:00:00-05:00   463.339996   466.380005   463.339996   466.380005   \n",
       "1993-12-20 00:00:00-05:00   466.380005   466.899994   465.529999   465.850006   \n",
       "...                                ...          ...          ...          ...   \n",
       "2025-07-16 00:00:00-04:00  6254.500000  6268.120117  6201.589844  6263.700195   \n",
       "2025-07-17 00:00:00-04:00  6263.399902  6304.689941  6262.270020  6297.359863   \n",
       "2025-07-18 00:00:00-04:00  6312.950195  6315.609863  6285.270020  6296.790039   \n",
       "2025-07-21 00:00:00-04:00  6304.740234  6336.080078  6303.790039  6305.600098   \n",
       "2025-07-22 00:00:00-04:00  6306.600098  6316.120117  6281.709961  6309.620117   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits     Tomorrow  \\\n",
       "Date                                                                          \n",
       "1993-12-14 00:00:00-05:00   275050000        0.0           0.0   461.839996   \n",
       "1993-12-15 00:00:00-05:00   331770000        0.0           0.0   463.339996   \n",
       "1993-12-16 00:00:00-05:00   284620000        0.0           0.0   466.380005   \n",
       "1993-12-17 00:00:00-05:00   363750000        0.0           0.0   465.850006   \n",
       "1993-12-20 00:00:00-05:00   255900000        0.0           0.0   465.299988   \n",
       "...                               ...        ...           ...          ...   \n",
       "2025-07-16 00:00:00-04:00  5177460000        0.0           0.0  6297.359863   \n",
       "2025-07-17 00:00:00-04:00  5512290000        0.0           0.0  6296.790039   \n",
       "2025-07-18 00:00:00-04:00  5184700000        0.0           0.0  6305.600098   \n",
       "2025-07-21 00:00:00-04:00  5010840000        0.0           0.0  6309.620117   \n",
       "2025-07-22 00:00:00-04:00  5662040000        0.0           0.0  6335.709961   \n",
       "\n",
       "                           Target  Close_Ratio_2  Trend_2  Close_Ratio_5  \\\n",
       "Date                                                                       \n",
       "1993-12-14 00:00:00-05:00       0       0.997157      1.0       0.996617   \n",
       "1993-12-15 00:00:00-05:00       1       0.998681      0.0       0.995899   \n",
       "1993-12-16 00:00:00-05:00       1       1.001621      1.0       0.999495   \n",
       "1993-12-17 00:00:00-05:00       0       1.003270      2.0       1.004991   \n",
       "1993-12-20 00:00:00-05:00       0       0.999431      1.0       1.003784   \n",
       "...                           ...            ...      ...            ...   \n",
       "2025-07-16 00:00:00-04:00       1       1.001594      1.0       1.000073   \n",
       "2025-07-17 00:00:00-04:00       0       1.002680      2.0       1.004904   \n",
       "2025-07-18 00:00:00-04:00       1       0.999955      1.0       1.003627   \n",
       "2025-07-21 00:00:00-04:00       1       1.000699      1.0       1.003846   \n",
       "2025-07-22 00:00:00-04:00       1       1.000319      2.0       1.002384   \n",
       "\n",
       "                           Trend_5  Close_Ratio_60  Trend_60  Close_Ratio_250  \\\n",
       "Date                                                                            \n",
       "1993-12-14 00:00:00-05:00      1.0        1.000283      32.0         1.028047   \n",
       "1993-12-15 00:00:00-05:00      1.0        0.997329      32.0         1.025151   \n",
       "1993-12-16 00:00:00-05:00      2.0        1.000311      32.0         1.028274   \n",
       "1993-12-17 00:00:00-05:00      3.0        1.006561      32.0         1.034781   \n",
       "1993-12-20 00:00:00-05:00      2.0        1.005120      32.0         1.033359   \n",
       "...                            ...             ...       ...              ...   \n",
       "2025-07-16 00:00:00-04:00      3.0        1.059076      38.0         1.080486   \n",
       "2025-07-17 00:00:00-04:00      3.0        1.061360      39.0         1.085761   \n",
       "2025-07-18 00:00:00-04:00      3.0        1.058264      38.0         1.085099   \n",
       "2025-07-21 00:00:00-04:00      3.0        1.056992      38.0         1.086018   \n",
       "2025-07-22 00:00:00-04:00      4.0        1.055234      38.0         1.086153   \n",
       "\n",
       "                           Trend_250  Close_Ratio_1000  Trend_1000  \n",
       "Date                                                                \n",
       "1993-12-14 00:00:00-05:00      127.0          1.176082       512.0  \n",
       "1993-12-15 00:00:00-05:00      126.0          1.172676       512.0  \n",
       "1993-12-16 00:00:00-05:00      127.0          1.176163       513.0  \n",
       "1993-12-17 00:00:00-05:00      128.0          1.183537       514.0  \n",
       "1993-12-20 00:00:00-05:00      128.0          1.181856       513.0  \n",
       "...                              ...               ...         ...  \n",
       "2025-07-16 00:00:00-04:00      140.0          1.315326       530.0  \n",
       "2025-07-17 00:00:00-04:00      141.0          1.321859       530.0  \n",
       "2025-07-18 00:00:00-04:00      141.0          1.321217       529.0  \n",
       "2025-07-21 00:00:00-04:00      142.0          1.322543       529.0  \n",
       "2025-07-22 00:00:00-04:00      142.0          1.322856       530.0  \n",
       "\n",
       "[7954 rows x 19 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22443d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=200,min_samples_split=50,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58cf0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test, predictors, model):\n",
    "    model.fit(train[predictors], train[\"Target\"])\n",
    "    preds = model.predict(test[predictors])[:,1]\n",
    "    preds[preds>=.6]=1\n",
    "    preds[preds<.6]=0\n",
    "    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n",
    "    combined = pd.concat([test[\"Target\"], preds], axis=1)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb0ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2500, step=250):\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[0:i].copy()\n",
    "        test = data.iloc[i:(i+step)].copy()\n",
    "\n",
    "        preds = predict(train, test, predictors, model)\n",
    "        all_predictions.append(preds)\n",
    "\n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ae9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download full historical data for S&P 500\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "sp500 = sp500.history(period=\"max\")\n",
    "\n",
    "# Add tomorrow's close and target column\n",
    "sp500[\"Tomorrow\"] = sp500[\"Close\"].shift(-1)\n",
    "sp500[\"Target\"] = (sp500[\"Tomorrow\"] > sp500[\"Close\"]).astype(int)\n",
    "\n",
    "# Make a copy for modeling\n",
    "sp500_data = sp500.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55279824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "predictors = [\"Close\"]  # or your feature list like `new_predictors`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9918f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test, predictors, model):\n",
    "    model.fit(train[predictors], train[\"Target\"])\n",
    "    preds = model.predict(test[predictors])\n",
    "    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n",
    "    combined = pd.concat([test[\"Target\"], preds], axis=1)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e962db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2500, step=250):\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[0:i].copy()\n",
    "        test = data.iloc[i:(i+step)].copy()\n",
    "        \n",
    "        preds = predict(train, test, predictors, model)\n",
    "        all_predictions.append(preds)\n",
    "\n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce73631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample predictors list\n",
    "predictors = [\"close_ratio_2\", \"Trend_2\"]  # adjust to your column names\n",
    "\n",
    "# Example model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define predict function\n",
    "def predict(train, test, predictors, model):\n",
    "    model.fit(train[predictors], train[\"Target\"])\n",
    "    preds = model.predict(test[predictors])\n",
    "    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n",
    "    combined = pd.concat([test[\"Target\"], preds], axis=1)\n",
    "    return combined\n",
    "\n",
    "# Define backtest function\n",
    "def backtest(data, model, predictors, start=2500, step=250):\n",
    "    all_predictions = []\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[0:i].copy()\n",
    "        test = data.iloc[i:(i+step)].copy()\n",
    "        preds = predict(train, test, predictors, model)\n",
    "        all_predictions.append(preds)\n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86912694",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['close_ratio_2', 'Trend_2'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mbacktest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp500_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mbacktest\u001b[39m\u001b[34m(data, model, predictors, start, step)\u001b[39m\n\u001b[32m     22\u001b[39m     train = data.iloc[\u001b[32m0\u001b[39m:i].copy()\n\u001b[32m     23\u001b[39m     test = data.iloc[i:(i+step)].copy()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     preds = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     all_predictions.append(preds)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.concat(all_predictions)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(train, test, predictors, model)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(train, test, predictors, model):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     model.fit(\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m]\u001b[49m, train[\u001b[33m\"\u001b[39m\u001b[33mTarget\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     13\u001b[39m     preds = model.predict(test[predictors])\n\u001b[32m     14\u001b[39m     preds = pd.Series(preds, index=test.index, name=\u001b[33m\"\u001b[39m\u001b[33mPredictions\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['close_ratio_2', 'Trend_2'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "predictions = backtest(sp500_data, model, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17410fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits',\n",
      "       'Tomorrow', 'Target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sp500_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7819f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['close_ratio_2', 'Trend_2']\n"
     ]
    }
   ],
   "source": [
    "print(predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34df8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [2, 5, 60, 250, 1000]\n",
    "new_predictors = []\n",
    "for horizon in horizons:\n",
    "    sp500_data[f\"close_ratio_{horizon}\"] = ...\n",
    "    sp500_data[f\"Trend_{horizon}\"] = ...\n",
    "    new_predictors += [f\"close_ratio_{horizon}\", f\"Trend_{horizon}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db31b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = new_predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1d93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2012317",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [2, 5, 60, 250, 1000]\n",
    "new_predictors = []\n",
    "\n",
    "for horizon in horizons:\n",
    "    rolling_avg = sp500_data[\"Close\"].rolling(horizon).mean()\n",
    "    ratio_column = f\"close_ratio_{horizon}\"\n",
    "    trend_column = f\"Trend_{horizon}\"\n",
    "\n",
    "    sp500_data[ratio_column] = sp500_data[\"Close\"] / rolling_avg\n",
    "    sp500_data[trend_column] = sp500_data[\"Target\"].shift(1).rolling(horizon).sum()\n",
    "\n",
    "    new_predictors += [ratio_column, trend_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6fcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = new_predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40380c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mbacktest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp500_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mbacktest\u001b[39m\u001b[34m(data, model, predictors, start, step)\u001b[39m\n\u001b[32m     22\u001b[39m     train = data.iloc[\u001b[32m0\u001b[39m:i].copy()\n\u001b[32m     23\u001b[39m     test = data.iloc[i:(i+step)].copy()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     preds = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     all_predictions.append(preds)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.concat(all_predictions)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(train, test, predictors, model)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(train, test, predictors, model):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTarget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     preds = model.predict(test[predictors])\n\u001b[32m     14\u001b[39m     preds = pd.Series(preds, index=test.index, name=\u001b[33m\"\u001b[39m\u001b[33mPredictions\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1239\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m check_classification_targets(y)\n\u001b[32m   1249\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "predictions = backtest(sp500_data, model, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b6375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2500, step=250):\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train = data.iloc[0:i].copy()\n",
    "        test = data.iloc[i:(i + step)].copy()\n",
    "\n",
    "        # Drop rows with NaNs in predictors\n",
    "        train = train.dropna(subset=predictors + [\"Target\"])\n",
    "        test = test.dropna(subset=predictors + [\"Target\"])\n",
    "\n",
    "        preds = predict(train, test, predictors, model)\n",
    "        all_predictions.append(preds)\n",
    "\n",
    "    return pd.concat(all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e63ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [2, 5, 60, 250, 1000]\n",
    "predictors = []\n",
    "\n",
    "for horizon in horizons:\n",
    "    ratio_col = f\"close_ratio_{horizon}\"\n",
    "    trend_col = f\"Trend_{horizon}\"\n",
    "\n",
    "    rolling_avg = sp500_data[\"Close\"].rolling(horizon).mean()\n",
    "    sp500_data[ratio_col] = sp500_data[\"Close\"] / rolling_avg\n",
    "    sp500_data[trend_col] = sp500_data[\"Target\"].shift(1).rolling(horizon).sum()\n",
    "\n",
    "    predictors += [ratio_col, trend_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "368e6d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\PADMA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "predictions = backtest(sp500_data, model, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ff5988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predictions\n",
       "1    16514\n",
       "0     5491\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"Predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77a2569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.5350006055468087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(predictions[\"Target\"], predictions[\"Predictions\"])\n",
    "print(\"Precision Score:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbe391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
